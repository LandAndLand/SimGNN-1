{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('normal')",
   "metadata": {
    "interpreter": {
     "hash": "f00aa4d08b5dbe9a4f4240f8270de016ce9f4f5bdff9dc19e01b094329a335d5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '../dataset/train/'\n",
    "testing_path = '../dataset/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['../dataset/train\\\\0.json', '../dataset/train\\\\1.json', '../dataset/train\\\\10.json', '../dataset/train\\\\11.json', '../dataset/train\\\\12.json', '../dataset/train\\\\13.json', '../dataset/train\\\\14.json', '../dataset/train\\\\15.json', '../dataset/train\\\\16.json', '../dataset/train\\\\17.json', '../dataset/train\\\\18.json', '../dataset/train\\\\19.json', '../dataset/train\\\\2.json', '../dataset/train\\\\20.json', '../dataset/train\\\\21.json', '../dataset/train\\\\22.json', '../dataset/train\\\\23.json', '../dataset/train\\\\24.json', '../dataset/train\\\\25.json', '../dataset/train\\\\26.json', '../dataset/train\\\\27.json', '../dataset/train\\\\28.json', '../dataset/train\\\\29.json', '../dataset/train\\\\3.json', '../dataset/train\\\\30.json', '../dataset/train\\\\31.json', '../dataset/train\\\\32.json', '../dataset/train\\\\33.json', '../dataset/train\\\\34.json', '../dataset/train\\\\35.json', '../dataset/train\\\\36.json', '../dataset/train\\\\37.json', '../dataset/train\\\\38.json', '../dataset/train\\\\39.json', '../dataset/train\\\\4.json', '../dataset/train\\\\40.json', '../dataset/train\\\\41.json', '../dataset/train\\\\42.json', '../dataset/train\\\\43.json', '../dataset/train\\\\44.json', '../dataset/train\\\\45.json', '../dataset/train\\\\46.json', '../dataset/train\\\\47.json', '../dataset/train\\\\48.json', '../dataset/train\\\\49.json', '../dataset/train\\\\5.json', '../dataset/train\\\\6.json', '../dataset/train\\\\7.json', '../dataset/train\\\\8.json', '../dataset/train\\\\9.json']\n"
     ]
    }
   ],
   "source": [
    "training_graphs = glob.glob(training_path +'*.json')\n",
    "print(training_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2040.66it/s]\n",
      "16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_graphs = glob.glob(training_path + \"*.json\")\n",
    "testing_graphs = glob.glob(testing_path + \"*.json\")\n",
    "graph_pairs = training_graphs + testing_graphs\n",
    "global_labels = set()\n",
    "# 预处理所有的graph\n",
    "for graph_pair in tqdm(graph_pairs):\n",
    "    data = json.load(open(graph_pair))\n",
    "    #print(data)\n",
    "    global_labels = global_labels.union(set(data[\"labels_1\"]))\n",
    "    global_labels = global_labels.union(set(data[\"labels_2\"]))\n",
    "global_labels = list(global_labels)\n",
    "global_labels = {val:index  for index, val in enumerate(global_labels)}\n",
    "number_of_labels = len(global_labels)\n",
    "\n",
    "print()\n",
    "print(number_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch: 100%|██████████| 100/100 [00:20<00:00,  4.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import time\n",
    "for i in trange(100, leave=True, desc=\"Epoch\"):\n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'labels_1': ['11', '11', '9', '11', '10', '7', '13', '11', '10', '9', '11', '8', '8', '10', '13'], 'labels_2': ['8', '11', '5', '11', '9', '7', '9', '7', '12', '11', '11', '11', '10', '10', '14'], 'graph_2': [[0, 1], [0, 4], [0, 5], [0, 8], [0, 11], [0, 12], [0, 13], [0, 14], [1, 2], [1, 3], [1, 6], [1, 7], [1, 8], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [2, 9], [2, 12], [2, 5], [2, 14], [3, 4], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [4, 6], [4, 8], [4, 9], [4, 10], [4, 11], [4, 13], [4, 14], [5, 7], [5, 9], [5, 10], [5, 13], [5, 14], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 14], [7, 8], [7, 9], [7, 10], [7, 14], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [9, 10], [9, 11], [9, 13], [9, 14], [10, 11], [10, 12], [10, 14], [11, 12], [11, 13], [11, 14], [12, 13], [12, 14], [13, 14]], 'ged': 11, 'graph_1': [[0, 1], [0, 2], [0, 3], [0, 4], [0, 6], [0, 7], [0, 8], [0, 10], [0, 12], [0, 13], [0, 14], [1, 3], [1, 4], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 13], [1, 14], [2, 5], [2, 6], [2, 7], [2, 9], [2, 10], [2, 11], [2, 12], [2, 14], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 11], [3, 13], [3, 14], [4, 5], [4, 6], [4, 8], [4, 9], [4, 10], [4, 13], [4, 14], [5, 6], [5, 7], [5, 12], [5, 13], [6, 7], [6, 8], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [7, 8], [7, 9], [7, 10], [7, 12], [7, 14], [8, 9], [8, 10], [8, 12], [8, 14], [9, 10], [9, 11], [9, 14], [10, 11], [10, 13], [10, 14], [11, 13], [11, 14], [12, 13], [12, 14], [13, 14]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.load(open('../dataset/train/0.json'))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0, 1], [0, 2], [0, 3], [0, 4], [0, 6], [0, 7], [0, 8], [0, 10], [0, 12], [0, 13], [0, 14], [1, 3], [1, 4], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 13], [1, 14], [2, 5], [2, 6], [2, 7], [2, 9], [2, 10], [2, 11], [2, 12], [2, 14], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 11], [3, 13], [3, 14], [4, 5], [4, 6], [4, 8], [4, 9], [4, 10], [4, 13], [4, 14], [5, 6], [5, 7], [5, 12], [5, 13], [6, 7], [6, 8], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [7, 8], [7, 9], [7, 10], [7, 12], [7, 14], [8, 9], [8, 10], [8, 12], [8, 14], [9, 10], [9, 11], [9, 14], [10, 11], [10, 13], [10, 14], [11, 13], [11, 14], [12, 13], [12, 14], [13, 14], [1, 0], [2, 0], [3, 0], [4, 0], [6, 0], [7, 0], [8, 0], [10, 0], [12, 0], [13, 0], [14, 0], [3, 1], [4, 1], [6, 1], [7, 1], [8, 1], [9, 1], [10, 1], [11, 1], [13, 1], [14, 1], [5, 2], [6, 2], [7, 2], [9, 2], [10, 2], [11, 2], [12, 2], [14, 2], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [9, 3], [11, 3], [13, 3], [14, 3], [5, 4], [6, 4], [8, 4], [9, 4], [10, 4], [13, 4], [14, 4], [6, 5], [7, 5], [12, 5], [13, 5], [7, 6], [8, 6], [10, 6], [11, 6], [12, 6], [13, 6], [14, 6], [8, 7], [9, 7], [10, 7], [12, 7], [14, 7], [9, 8], [10, 8], [12, 8], [14, 8], [10, 9], [11, 9], [14, 9], [11, 10], [13, 10], [14, 10], [13, 11], [14, 11], [13, 12], [14, 12], [14, 13]]\n"
     ]
    }
   ],
   "source": [
    "#data['graph_1']\n",
    "#for x, y in data[\"graph_1\"]:\n",
    "#    print(x, y)\n",
    "# 边记为 e ， 则edges_1的尺寸为 2e * 2\n",
    "edges_1 = data[\"graph_1\"] + [[y, x] for x, y in data[\"graph_1\"]]\n",
    "print(edges_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  2  2  2\n   2  2  2  2  2  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  5  5  5\n   5  6  6  6  6  6  6  6  7  7  7  7  7  8  8  8  8  9  9  9 10 10 10 11\n  11 12 12 13  1  2  3  4  6  7  8 10 12 13 14  3  4  6  7  8  9 10 11 13\n  14  5  6  7  9 10 11 12 14  4  5  6  7  8  9 11 13 14  5  6  8  9 10 13\n  14  6  7 12 13  7  8 10 11 12 13 14  8  9 10 12 14  9 10 12 14 10 11 14\n  11 13 14 13 14 13 14 14]\n [ 1  2  3  4  6  7  8 10 12 13 14  3  4  6  7  8  9 10 11 13 14  5  6  7\n   9 10 11 12 14  4  5  6  7  8  9 11 13 14  5  6  8  9 10 13 14  6  7 12\n  13  7  8 10 11 12 13 14  8  9 10 12 14  9 10 12 14 10 11 14 11 13 14 13\n  14 13 14 14  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1\n   1  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4\n   4  5  5  5  5  6  6  6  6  6  6  6  7  7  7  7  7  8  8  8  8  9  9  9\n  10 10 10 11 11 12 12 13]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "edges_1_T = np.array(edges_1, dtype=np.int64).T\n",
    "# edges_1_T的尺寸为 2* 2e; 上面的行是出发顶点；下面的行是目标顶点\n",
    "print(edges_1_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['11', '11', '9', '11', '10', '7', '13', '11', '10', '9', '11', '8', '8', '10', '13']\n15\n"
     ]
    }
   ],
   "source": [
    "print(data[\"labels_1\"])\n",
    "print(len(data[\"labels_1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n",
       "          6,  6,  7,  7,  7,  7,  7,  8,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11,\n",
       "         11, 12, 12, 13,  1,  2,  3,  4,  6,  7,  8, 10, 12, 13, 14,  3,  4,  6,\n",
       "          7,  8,  9, 10, 11, 13, 14,  5,  6,  7,  9, 10, 11, 12, 14,  4,  5,  6,\n",
       "          7,  8,  9, 11, 13, 14,  5,  6,  8,  9, 10, 13, 14,  6,  7, 12, 13,  7,\n",
       "          8, 10, 11, 12, 13, 14,  8,  9, 10, 12, 14,  9, 10, 12, 14, 10, 11, 14,\n",
       "         11, 13, 14, 13, 14, 13, 14, 14],\n",
       "        [ 1,  2,  3,  4,  6,  7,  8, 10, 12, 13, 14,  3,  4,  6,  7,  8,  9, 10,\n",
       "         11, 13, 14,  5,  6,  7,  9, 10, 11, 12, 14,  4,  5,  6,  7,  8,  9, 11,\n",
       "         13, 14,  5,  6,  8,  9, 10, 13, 14,  6,  7, 12, 13,  7,  8, 10, 11, 12,\n",
       "         13, 14,  8,  9, 10, 12, 14,  9, 10, 12, 14, 10, 11, 14, 11, 13, 14, 13,\n",
       "         14, 13, 14, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  6,\n",
       "          6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  8,  8,  8,  8,  9,  9,  9,\n",
       "         10, 10, 10, 11, 11, 12, 12, 13]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.from_numpy(edges_1_T).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11\n0.7333333333333333\n[[0.4803053]]\ntensor([[0.4803]], dtype=torch.float64)\ntensor([0.4803], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(data['ged'])\n",
    "norm_ged = data[\"ged\"]/(0.5*(len(data[\"labels_1\"])+len(data[\"labels_2\"])))\n",
    "print(norm_ged)\n",
    "print(np.exp(-norm_ged).reshape(1, 1))\n",
    "print(torch.from_numpy(np.exp(-norm_ged).reshape(1, 1)))\n",
    "print(torch.from_numpy(np.exp(-norm_ged).reshape(1, 1)).view(-1))\n",
    "#torch.from_numpy(np.exp(-norm_ged).reshape(1, 1)).view(-1).float()"
   ]
  },
  {
   "source": [
    "### labels_1 和 labels_2 应该是图节点的取值"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['11',\n",
       " '11',\n",
       " '9',\n",
       " '11',\n",
       " '10',\n",
       " '7',\n",
       " '13',\n",
       " '11',\n",
       " '10',\n",
       " '9',\n",
       " '11',\n",
       " '8',\n",
       " '8',\n",
       " '10',\n",
       " '13']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "data['labels_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['8',\n",
       " '11',\n",
       " '5',\n",
       " '11',\n",
       " '9',\n",
       " '7',\n",
       " '9',\n",
       " '7',\n",
       " '12',\n",
       " '11',\n",
       " '11',\n",
       " '11',\n",
       " '10',\n",
       " '10',\n",
       " '14']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "data['labels_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "x=torch.arange(15).view(5,3)\n",
    "x=x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6., 7., 8.])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "torch.mean(x,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}